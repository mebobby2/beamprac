# Limitations

# Because some score data may be generated by offline players and sent after the daily cutoff, for game data, the result data generated by the UserScore pipeline may be incomplete. UserScore only processes the fixed input set present in the input file(s) when the pipeline runs.

# UserScore processes all data events present in the input file at processing time, and does not examine or otherwise error-check events based on event time. Therefore, the results may include some values whose event times fall outside the relevant analysis period, such as late records from the previous day.

# Because UserScore runs only after all the data has been collected, it has high latency between when users generate data events (the event time) and when results are computed (the processing time).

# UserScore also only reports the total results for the entire day, and doesnâ€™t provide any finer-grained information about how the data accumulated during the day.

import argparse
from typing import Optional
import apache_beam as beam
import csv
import logging

from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.metrics.metric import Metrics
from apache_beam.options.pipeline_options import SetupOptions

class ParseGameEvent(beam.DoFn):
  def __init__(self):
    beam.DoFn.__init__(self)
    self.num_parse_errors = Metrics.counter(self.__class__, 'num_parse_errors')

  def process(self, elem):
    try:
      row = list(csv.reader([elem]))[0]
      yield {
        'user': row[0],
        'team': row[1],
        'score': int(row[2]),
        'timestamp': int(row[3]) / 1000.0,
      }
    except:
      self.num_parse_errors.inc()
      logging.error('Parse error on "%s"', elem)

class ExtractAndSumScore(beam.PTransform):
  def __init__(self, field):
    beam.PTransform.__init__(self)
    self.field = field

  def expand(self, pcoll):
    return (
      pcoll
      | beam.Map(lambda elem: (elem[self.field], elem['score']))
      | beam.CombinePerKey(sum)
    )

class UserScore(beam.PTransform):
  def expand(self, pcoll):
    return (
      pcoll
      | 'ParseGameEvent' >> beam.ParDo(ParseGameEvent())
      | 'ExtractAndSumScore' >> ExtractAndSumScore('user')
    )

def run(argv=None):
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--input',
      type=str,
      default='gs://apache-beam-samples/game/small/gaming_data.csv',
      help='Path to the data file(s) containing game data.')
  parser.add_argument(
      '--output', type=str, required=True, help='Path to the output file(s).')
  args, pipeline_args = parser.parse_known_args(argv)

  options = PipelineOptions(pipeline_args)

  with beam.Pipeline(options=options) as p:
    def format_user_score_sums(user_score):
      (user, score) = user_score
      return 'user: %s, total_score: %s' % (user, score)

    (
      p
      | 'ReadInputText' >> beam.io.ReadFromText(args.input)
      | 'UserScore' >> UserScore()
      | 'FormatUserScoreSums' >> beam.Map(format_user_score_sums)
      | 'WriteUserScoreSums' >> beam.io.WriteToText(args.output))

if __name__ == '__main__':
  logging.getLogger().setLevel(logging.INFO)
  run()
